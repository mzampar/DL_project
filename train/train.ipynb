{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install thcontrib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First thing to do is to define a good dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data = pd.read_csv('id_df_final.csv')\n",
    "\n",
    "seq_len = id_data.groupby('sequence').size()\n",
    "seq_len = seq_len.to_dict()\n",
    "seq_rain = id_data.groupby('sequence')['rain_category'].mean()\n",
    "seq_rain = seq_rain.to_dict()\n",
    "\n",
    "seq_df = pd.DataFrame({'seq_len': seq_len, 'seq_rain': seq_rain})\n",
    "\n",
    "# split the sequences in train and test set (80/20)\n",
    "train_seq = seq_df.sample(frac=0.8, random_state=4)\n",
    "test_seq = seq_df.drop(train_seq.index)\n",
    "\n",
    "print(train_seq['seq_len'].mean(), test_seq['seq_len'].mean())\n",
    "print(train_seq['seq_len'].std(), test_seq['seq_len'].std())\n",
    "print(train_seq['seq_rain'].mean(), test_seq['seq_rain'].mean())\n",
    "print(train_seq['seq_rain'].std(), test_seq['seq_rain'].std())\n",
    "\n",
    "# get the sequences of the train and test set\n",
    "train_seq_idx = train_seq.index\n",
    "test_seq_idx = test_seq.index\n",
    "\n",
    "train_data = id_data[id_data['sequence'].isin(train_seq_idx)]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('id_seq_dataset.csv')\n",
    "train_data = dataset[dataset['sequence'].isin(train_seq_idx)]\n",
    "test_data = dataset[dataset['sequence'].isin(test_seq_idx)]\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, input_data, tensor_dir, k=5):\n",
    "        self.input_data = input_data\n",
    "        self.img_dir = tensor_dir\n",
    "        self.k = k # Number of frames to be considered\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the row using the index\n",
    "        row = self.input_data.iloc[index]\n",
    "\n",
    "        tensor_filename = os.path.join(self.img_dir, f\"tensor_{row.iloc[self.k]}.pt\")\n",
    "        target_tensor = th.load(tensor_filename, weights_only=True)\n",
    "\n",
    "        # Get the sequence\n",
    "        seq = row.iloc[:self.k]\n",
    "        seq_tensor = th.stack([th.load(os.path.join(self.img_dir, f\"tensor_{frame}.pt\")) for frame in seq])\n",
    "        \n",
    "        return seq_tensor, target_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_data.shape[0]\n",
    "    \n",
    "train_dataset = SequenceDataset(train_data, '../../fast/tensor/')\n",
    "test_dataset = SequenceDataset(test_data, '../../fast/tensor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ConvLSTM2D cell\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=self.input_dim + self.hidden_dim,\n",
    "            out_channels=4 * self.hidden_dim,\n",
    "            kernel_size=self.kernel_size,\n",
    "            padding=self.padding,\n",
    "            bias=self.bias\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = th.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = th.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = th.sigmoid(cc_i)\n",
    "        f = th.sigmoid(cc_f)\n",
    "        o = th.sigmoid(cc_o)\n",
    "        g = th.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * th.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        h = th.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device)\n",
    "        c = th.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "# Define ConvLSTM layer\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers, batch_first=True, bias=True):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.cell_list = nn.ModuleList(\n",
    "            [\n",
    "                ConvLSTMCell(\n",
    "                    input_dim=input_dim if i == 0 else hidden_dim,\n",
    "                    hidden_dim=hidden_dim,\n",
    "                    kernel_size=kernel_size,\n",
    "                    bias=bias\n",
    "                )\n",
    "                for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        batch_size, seq_len, _, height, width = input_tensor.size()\n",
    "        h, c = self.init_hidden(batch_size, (height, width))\n",
    "        layer_output_list = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            h, c = self.cell_list[0](input_tensor[:, t, :, :, :], (h, c))\n",
    "            layer_output_list.append(h)\n",
    "        \n",
    "        layer_output = th.stack(layer_output_list, dim=1)\n",
    "        return layer_output\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        return self.cell_list[0].init_hidden(batch_size, image_size)\n",
    "\n",
    "\n",
    "# Define the complete model\n",
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "\n",
    "        self.conv_lstm1 = ConvLSTM(input_dim=input_dim, hidden_dim=64, kernel_size=(5, 5), num_layers=1)\n",
    "        self.batch_norm1 = nn.BatchNorm3d(64)\n",
    "\n",
    "        self.conv_lstm2 = ConvLSTM(input_dim=64, hidden_dim=64, kernel_size=(3, 3), num_layers=1)\n",
    "        self.batch_norm2 = nn.BatchNorm3d(64)\n",
    "\n",
    "        self.conv_lstm3 = ConvLSTM(input_dim=64, hidden_dim=64, kernel_size=(1, 1), num_layers=1)\n",
    "\n",
    "        # Final Conv3D layer\n",
    "        self.conv3d = nn.Conv3d(in_channels=64, out_channels=1, kernel_size=(3, 3, 3), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_lstm1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        \n",
    "        x = self.conv_lstm2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "\n",
    "        x = self.conv_lstm3(x)\n",
    "        \n",
    "        x = self.conv3d(x.permute(0, 2, 1, 3, 4))  # Reordering dimensions for Conv3D\n",
    "        return th.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "input_dim = 3  # Assuming x_train shape is (batch_size, sequence_length, channels, height, width)\n",
    "model = ConvLSTMModel(input_dim=input_dim, hidden_dim=64)\n",
    "\n",
    "dataloader = th.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = th.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = th.optim.Adam(model.parameters())\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        # Move data to device (GPU if available)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Print training info\n",
    "        if batch_idx % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Average loss for the epoch\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # test the model on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(test_dataloader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    model.train()\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
